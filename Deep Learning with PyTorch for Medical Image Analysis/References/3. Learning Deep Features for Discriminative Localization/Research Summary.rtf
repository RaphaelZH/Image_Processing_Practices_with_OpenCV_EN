{\rtf1\ansi\ansicpg1252\cocoartf2757
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 The paper begins by discussing the limitations of traditional convolutional neural networks (CNNs) in object localization tasks. CNNs are typically trained on image-level labels, which means that they can recognize the presence of an object in an image but cannot localize it accurately. The authors propose a new approach that uses global average pooling to enable CNNs to have remarkable localization ability.\
\
The proposed approach involves replacing the fully connected layers of a CNN with global average pooling layers. Global average pooling computes the average of each feature map in the final convolutional layer, resulting in a fixed-length feature vector that represents the entire image. This feature vector can then be used to classify the image and to generate a localization map that highlights the most discriminative regions of the image.\
\
The authors demonstrate the effectiveness of their approach on a variety of tasks, including object localization, scene classification, and concept localization. They use the ImageNet dataset to evaluate their approach on object localization, achieving a top-5 error of 7.32%, which is significantly better than the previous state-of-the-art. They also show that their approach can be applied to scene classification tasks, achieving an accuracy of 82.8% on the SUN dataset.\
\
To evaluate their approach on concept localization tasks, the authors use the MIT Places dataset, which contains weakly labeled images. They use a hard-negative mining algorithm to learn concept detectors and apply their CAM technique to localize concepts in the image. The authors show that their approach can accurately localize concepts in weakly labeled images, achieving an accuracy of 47.5% on the MIT Places dataset.\
\
The authors also compare the performance of their approach with other state-of-the-art methods, including AlexNet and GoogLeNet. They show that their approach outperforms AlexNet and performs similarly to GoogLeNet, despite having fewer convolutional layers. They also demonstrate that the localization maps generated using their CAM technique are informative even in scenarios where the images are weakly labeled.\
\
Overall, the authors demonstrate that global average pooling can enable CNNs to have remarkable localization ability, even when trained on image-level}