{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a842b0f",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1ce9da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:39.107384Z",
     "start_time": "2022-12-22T11:17:37.962479Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "#from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn import datasets\n",
    "\n",
    "import matplotlib as mpl\n",
    "#from matplotlib.colors import LinearSegmentedColormap\n",
    "#from matplotlib.patches import ConnectionPatch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import reprlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded84abf",
   "metadata": {},
   "source": [
    "# Configuring Visualization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ac9d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:39.116074Z",
     "start_time": "2022-12-22T11:17:39.108908Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e49c41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:39.118651Z",
     "start_time": "2022-12-22T11:17:39.116900Z"
    }
   },
   "outputs": [],
   "source": [
    "XINHUI = \"#7a7374\"\n",
    "XUEBAI = \"#fffef9\"\n",
    "YINBAI = \"#f1f0ed\"\n",
    "YINHUI = \"#918072\"\n",
    "\n",
    "figure_size = (16, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db07ff94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:39.121855Z",
     "start_time": "2022-12-22T11:17:39.119532Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_params = {\n",
    "    \"axes.axisbelow\": True,\n",
    "    \"axes.edgecolor\": YINBAI,\n",
    "    \"axes.facecolor\": XUEBAI,\n",
    "    \"axes.grid\": True,\n",
    "    \"axes.labelcolor\": XINHUI,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.titlecolor\": XINHUI,\n",
    "    \"figure.edgecolor\": YINBAI,\n",
    "    \"figure.facecolor\": XUEBAI,\n",
    "    \"grid.alpha\": .8,\n",
    "    \"grid.color\": YINBAI,\n",
    "    \"grid.linestyle\": \"--\",\n",
    "    \"grid.linewidth\": 1.2,\n",
    "    \"legend.edgecolor\": YINHUI,\n",
    "    \"patch.edgecolor\": XUEBAI,\n",
    "    \"patch.force_edgecolor\": True,\n",
    "    \"text.color\": XINHUI,\n",
    "    \"xtick.color\": YINHUI,\n",
    "    \"ytick.color\": YINHUI,\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(custom_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a413b95",
   "metadata": {},
   "source": [
    "# Configuring Other Notebook Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e4bf0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:39.124296Z",
     "start_time": "2022-12-22T11:17:39.122794Z"
    }
   },
   "outputs": [],
   "source": [
    "#reprlib_rules = reprlib.Repr()\n",
    "#reprlib_rules.maxother = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c34db",
   "metadata": {},
   "source": [
    "# Pre-installing Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17737b1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:39.128029Z",
     "start_time": "2022-12-22T11:17:39.126611Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8c08876",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:39.300318Z",
     "start_time": "2022-12-22T11:17:39.129143Z"
    }
   },
   "outputs": [],
   "source": [
    "from Modules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be86911",
   "metadata": {},
   "source": [
    "# Practicing in Stages\n",
    "\n",
    "## Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "403f139c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:39.349420Z",
     "start_time": "2022-12-22T11:17:39.301672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[32mLoading and transformation of the MNIST dataset\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[32m    +--------------------------------------------------------+\u001b[0m\n",
      "\u001b[1m\u001b[32m    | Statement                                              |\u001b[0m\n",
      "\u001b[1m\u001b[32m    +--------------------------------------------------------+\u001b[0m\n",
      "\u001b[1m\u001b[32m    | transform = transforms.Compose(                        |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |     [transforms.ToTensor(),                            |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |      transforms.Normalize((0.5, ), (0.5, ))])          |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                                                        |\u001b[0m\n",
      "\u001b[1m\u001b[32m    | training_dataset = datasets.MNIST(root=\"../Datasets\",  |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                                   train=True,          |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                                   download=True,       |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                                   transform=transform) |\u001b[0m\n",
      "\u001b[1m\u001b[32m    +--------------------------------------------------------+\u001b[0m\n",
      "\u001b[1m\u001b[32m    +------------------+----------------------------------------+\u001b[0m\n",
      "\u001b[1m\u001b[32m    | Variable         | Value                                  |\u001b[0m\n",
      "\u001b[1m\u001b[32m    +------------------+----------------------------------------+\u001b[0m\n",
      "\u001b[1m\u001b[32m    | transform        | Compose(                               |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  |     ToTensor()                         |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  |     Normalize(mean=(0.5,), std=(0.5,)) |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  | )                                      |\u001b[0m\n",
      "\u001b[1m\u001b[32m    | training_dataset | Dataset MNIST                          |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  |     Number of datapoints: 60000        |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  |     Root location: ../Datasets         |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  |     Split: Train                       |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  |     StandardTransform                  |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  | Transform: Compose(                    |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  |                ToTensor()              |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  |                Normalize(mean=(0.5,),  |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  |         std=(0.5,))                    |\u001b[0m\n",
      "\u001b[1m\u001b[32m    |                  |            )                           |\u001b[0m\n",
      "\u001b[1m\u001b[32m    +------------------+----------------------------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "training_dataset = datasets.MNIST(root=\"../Datasets\",\n",
    "                                  train=True,\n",
    "                                  download=True,\n",
    "                                  transform=transform)\n",
    "\n",
    "tabulation = Form_Generator()\n",
    "font_colors_list = tabulation.color_selector()\n",
    "\n",
    "tabulation.heading_printer(\"Loading and transformation of the MNIST dataset\")\n",
    "\n",
    "statements = [\n",
    "    \"\"\"\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "training_dataset = datasets.MNIST(root=\"../Datasets\",\n",
    "                                  train=True,\n",
    "                                  download=True,\n",
    "                                  transform=transform)\n",
    "\"\"\"\n",
    "]\n",
    "tabulation.statement_generator(statements)\n",
    "\n",
    "variables = [\"transform\", \"training_dataset\"]\n",
    "values = [str(transform), str(training_dataset)]\n",
    "tabulation.variable_generator(variables, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad5575cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:43.906337Z",
     "start_time": "2022-12-22T11:17:39.350703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[37mConfiguration of the training batches\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[37m    +-----------------------------------------------------------+\u001b[0m\n",
      "\u001b[1m\u001b[37m    | Statement                                                 |\u001b[0m\n",
      "\u001b[1m\u001b[37m    +-----------------------------------------------------------+\u001b[0m\n",
      "\u001b[1m\u001b[37m    | training_loader =                                         |\u001b[0m\n",
      "\u001b[1m\u001b[37m    |     torch.utils.data.DataLoader(dataset=training_dataset, |\u001b[0m\n",
      "\u001b[1m\u001b[37m    |     batch_size=100,                                       |\u001b[0m\n",
      "\u001b[1m\u001b[37m    |     shuffle=True)                                         |\u001b[0m\n",
      "\u001b[1m\u001b[37m    +-----------------------------------------------------------+\u001b[0m\n",
      "\u001b[1m\u001b[37m    +--------------------------------------+----------------------+\u001b[0m\n",
      "\u001b[1m\u001b[37m    | Expression                           | Result               |\u001b[0m\n",
      "\u001b[1m\u001b[37m    +--------------------------------------+----------------------+\u001b[0m\n",
      "\u001b[1m\u001b[37m    | len(training_loader)                 | 600                  |\u001b[0m\n",
      "\u001b[1m\u001b[37m    | list(training_loader)[0][0].shape    | torch.Size([100, 1,  |\u001b[0m\n",
      "\u001b[1m\u001b[37m    |                                      |             28, 28]) |\u001b[0m\n",
      "\u001b[1m\u001b[37m    | list(training_loader)[0][1].shape    | torch.Size([100])    |\u001b[0m\n",
      "\u001b[1m\u001b[37m    | next(iter(training_loader))[0].shape | torch.Size([100, 1,  |\u001b[0m\n",
      "\u001b[1m\u001b[37m    |                                      |             28, 28]) |\u001b[0m\n",
      "\u001b[1m\u001b[37m    | next(iter(training_loader))[1].shape | torch.Size([100])    |\u001b[0m\n",
      "\u001b[1m\u001b[37m    +--------------------------------------+----------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "training_loader = torch.utils.data.DataLoader(dataset=training_dataset,\n",
    "                                              batch_size=100,\n",
    "                                              shuffle=True)\n",
    "\n",
    "tabulation = Form_Generator()\n",
    "tabulation.heading_printer(\"Configuration of the training batches\")\n",
    "\n",
    "statements = [\n",
    "    \"\"\"\n",
    "training_loader = torch.utils.data.DataLoader(dataset=training_dataset,\n",
    "                                              batch_size=100,\n",
    "                                              shuffle=True)\n",
    "\"\"\"\n",
    "]\n",
    "tabulation.long_statement_generator(statements)\n",
    "\n",
    "expressions = [\n",
    "    \"len(training_loader)\", \"list(training_loader)[0][0].shape\",\n",
    "    \"list(training_loader)[0][1].shape\",\n",
    "    \"next(iter(training_loader))[0].shape\",\n",
    "    \"next(iter(training_loader))[1].shape\"\n",
    "]\n",
    "results = [\n",
    "    str(len(training_loader)),\n",
    "    str(list(training_loader)[0][0].shape),\n",
    "    str(list(training_loader)[0][1].shape),\n",
    "    str(next(iter(training_loader))[0].shape),\n",
    "    str(next(iter(training_loader))[1].shape),\n",
    "]\n",
    "tabulation.expression_generator(expressions, results, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dce7311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:43.910220Z",
     "start_time": "2022-12-22T11:17:43.907408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[30mFunction definition for plotting tensor images\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[30m    +----------------------------------------------------------+\u001b[0m\n",
      "\u001b[1m\u001b[30m    | Definition                                               |\u001b[0m\n",
      "\u001b[1m\u001b[30m    +----------------------------------------------------------+\u001b[0m\n",
      "\u001b[1m\u001b[30m    | def im_convert(tensor):                                  |\u001b[0m\n",
      "\u001b[1m\u001b[30m    |     image = tensor.clone().detach().numpy()              |\u001b[0m\n",
      "\u001b[1m\u001b[30m    |     image = image.transpose(1, 2, 0)                     |\u001b[0m\n",
      "\u001b[1m\u001b[30m    |     image = image * np.array((0.5, 0.5, 0.5), (0.5, 0.5, |\u001b[0m\n",
      "\u001b[1m\u001b[30m    |     0.5))                                                |\u001b[0m\n",
      "\u001b[1m\u001b[30m    |     image = image.clip(0, 1)                             |\u001b[0m\n",
      "\u001b[1m\u001b[30m    |     return image                                         |\u001b[0m\n",
      "\u001b[1m\u001b[30m    +----------------------------------------------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def im_convert(tensor):\n",
    "    image = tensor.clone().detach().numpy()\n",
    "    image = image.transpose(1, 2, 0)\n",
    "    image = image * np.array((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    image = image.clip(0, 1)\n",
    "    return image\n",
    "\n",
    "\n",
    "tabulation = Form_Generator()\n",
    "tabulation.heading_printer(\"Function definition for plotting tensor images\")\n",
    "\n",
    "definitions = [\n",
    "    \"\"\"\n",
    "def im_convert(tensor):\n",
    "    image = tensor.clone().detach().numpy()\n",
    "    image = image.transpose(1, 2, 0)\n",
    "    image = image * np.array((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    image = image.clip(0, 1)\n",
    "    return image\n",
    "\"\"\"\n",
    "]\n",
    "tabulation.definition_generator(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c21d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:43.918371Z",
     "start_time": "2022-12-22T11:17:43.911381Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f358388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:43.931599Z",
     "start_time": "2022-12-22T11:17:43.919556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 3, 2, 4, 0, 8, 3, 7, 2, 3, 4, 3, 2, 5, 1, 2, 5, 6, 4, 6, 8, 7, 3,\n",
       "        3, 8, 6, 9, 1, 3, 4, 2, 7, 0, 7, 4, 2, 0, 1, 0, 4, 8, 6, 2, 0, 7, 1, 1,\n",
       "        5, 5, 1, 6, 8, 4, 0, 3, 1, 6, 3, 6, 1, 8, 9, 3, 0, 9, 0, 6, 5, 8, 0, 5,\n",
       "        5, 2, 6, 0, 1, 3, 0, 8, 0, 6, 8, 4, 4, 1, 3, 2, 9, 3, 9, 8, 8, 4, 2, 0,\n",
       "        2, 2, 0, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataiter)[0].shape\n",
    "\n",
    "next(dataiter)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13212b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T01:50:32.354869Z",
     "start_time": "2022-12-22T01:50:30.018540Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3aa37d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:43.934489Z",
     "start_time": "2022-12-22T11:17:43.932856Z"
    }
   },
   "outputs": [],
   "source": [
    "a = statements[0].strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08a071a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:43.937196Z",
     "start_time": "2022-12-22T11:17:43.935224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training_loader = torch.utils.data.DataLoader(dataset=training_dataset,', '                                              batch_size=100,', '                                              shuffle=True)']\n"
     ]
    }
   ],
   "source": [
    "for i in statements:\n",
    "    i = i.strip().split(\"\\n\")\n",
    "    map(lambda i: i.strip(), i)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a8bb8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:43.940405Z",
     "start_time": "2022-12-22T11:17:43.938291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training_loader = torch.utils.data.DataLoader(dataset=training_dataset,',\n",
       " '                                              batch_size=100,',\n",
       " '                                              shuffle=True)']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e438163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-22T11:17:43.951154Z",
     "start_time": "2022-12-22T11:17:43.943540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training_loader = torch.utils.data.DataLoader(dataset=training_dataset,',\n",
       " 'batch_size=100,',\n",
       " 'shuffle=True)']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda i: i.strip(), a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225659f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "345.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
